# Notes

### Randomized Controlled Trials in Medical AI 
- 123
### Ensuring Fairness in ML
- More of a case study

### Ethical Considerations of Using Machine Learning for Decision Support in Occupational Health: An Example Involving Periodic Workers' Health Assessments
**Source**: https://link.springer.com/content/pdf/10.1007/s10926-020-09895-x.pdf.  
**Summary**: Ethical assessment of the impact of Machine Learning Decision Support Tools in occupational health according to frameworks from medical ethics (Beauchamp and Childress) and philosophy of technology.
Ethical dilemmas arising from opposing principles.
Effects of technology on pre-existing problems.  
**Assessment**: not practical, not math. Strong on ethics. Very relevant, important discussion on several trade-offs.  
**Topics**:  
 - Philosophy of technology.
 - Beauchamp and Childress principles.
 - Case study.
 - Type: ethical deliberation.
 - Ethical issues typical of the application (problem) and of the technology (solution).
 - Conflict individual (data privacy etc.) => non-maleficence vs group => beneficence (trade-off).
 - Trade-off privacy vs predictability.
 - Trade-off non-discrimination vs predictability. 
 - Ethical dilemmas.


### Ethical limitations of algorithmic fairness solutions in health care machine learning
**Source**: https://www.thelancet.com/journals/landig/article/PIIS2589-7500(20)30065-0/fulltext.  
**Summary**: algorithmic solutions for bias are insufficient alone.
Identity could be a true predictor as well as a source of discrimination.
Fairness could reduce the efficacy of trained models, and bring to less effective treatment of patients.  
**Assessment**: Short, high-level, at most source of quotes.  
**Topics**:  
 - Insufficiency of algorithmic solutions to bias.
 - Trade-off fairness-predictability.
 - Non-maleficience vs justice.
 - Protected attributes as predictors vs as sources of unequal treatment.
