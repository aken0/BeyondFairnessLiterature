Machine Learning (ML) in health care and medicine has grown to be one of the most discussed, but also most promising applications of the ever-growing technology of ML.
In recent years, more and more research has shown ML to be an effective way of supporting health care practitioners in a great diversity of ways \cite{rajpurkar2022ai, topol2019high}.
However, there is also growing concern about the implications the deployment of ML has for the future of health care and medicine. 

While there are ongoing public discussions about ML replacing humans as workers in different ways \idea{[citation needed]}, many scholars have made clear that ML and AI tools will not replace clinicians in the near future but rather be integrated as support systems, for example as clinical decision support systems (CDSS) \cite{Morley2020}.

CDSS have been used since the 1980s with growing success \cite{sutton2020overview}.
Only in recent years, the involvement of Machine Learning in those systems has led to a new regulatory situation.
Still, their deployment and success can tell us a lot about the way to go with ML tools.
For example, although closed loop systems, i.e., systems were every step of the process from diagnosis to drug intake is computerized and monitored, do already exist they are not commonly used, partly due to costs but certainly also due to the involved surveillance environment for patients \cite{sutton2020overview}. 

% why medicine is an interesting field to clarify ethical problems, particularities
We consider CDSS a particularly interesting use case of ML when it comes to fairness and more generally ethical discussion, since the biomedical field historically played an important role when it comes to ethical principles and deliberations \cite{Toulmin1982}\cite{Hardin1989}.
It helped displace purely theoretical ethical deliberations (meta-ethics) to more concrete, unavoidable, and tangible questions (applied ethics).
It further helped replace purely relativist, subjectivist, and psychological investigations of ethics \cite{Toulmin1982}.
Broad, universal moral principles were replaced by case studies, for example arising in clinical medicine.
Finally, ethical considerations started taking into account the roles and relationships of the actors present (for example, by recognizing the authority relationship between doctors and patients).
Poetically put, ``Medicine saved the life of ethics'' \cite{Toulmin1982}.

Furthermore, medicine poses some inevitable moral dilemmas that can not be ignored, about which a substantial moral literature has been developed.
The high stakes found in some decisions in medicine might induce less care in implementing ideas about `fair distribution' and less readiness to sacrifice performance for fairness.
In health care settings, we are often interested in the prevention of harm rather than the allocation of goods (such as in job placements, college admissions, and other areas where fair-ML is being applied).
This means that solutions such as randomization of a group's predictions to ensure equal harms will be considered for example unacceptable.
A final point of interest is the fact that in medicine, sensitive attributes such as gender and race might be true predictors and avoiding group differences would harm everyone \cite{Mccradden2020}.

% methods and preview
In our investigations, we draw on literature from the fields of fair-ML, economics, medicine, biomedical ethics, and philosophy.
In \chapref{tradeoff}, we examine economists' work on the notion of trade-offs to derive a meaningful formalization of them.
We then examine trade-offs that are frequently discussed in the Machine Learning literature.
The analysis of the medical literature found in \chapref{medicine} helps us identify the trade-offs (often described as moral dilemmas) inherent to the field of health care.
We furthermore examine fairness problems in medical practice, and discuss the usefulness of principled approaches found in the bioethical literature in enlightening the ethical discussion about CDSS.
In \chapref{combination}, we relate fairness problems raised by the Fair-ML community to ethical questions raised in the medical field.
In particular, we argue that many problems are inherent to medical practice and not introduced by the application of Machine Learning.
We then examine what ML can positively contribute with respect to ethical issues in medicine.
Finally, in \chapref{new_tradeoff} we show how the application of Machine Learning to health care introduces new trade-offs and ethical questions.
We analyze the supporting literature critically, by discussing in which measure those questions can be found in ethical discussion about other technologies.
