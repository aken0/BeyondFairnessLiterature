Machine Learning (ML) in health care and medicine has grown to be one of the most discussed, but also most promising applications of the ever-growing technology of ML.
In recent years, more and more research has shown ML to be an effective way of supporting health care practitioners in a great diversity of ways \cite{rajpurkar2022ai, topol2019high}.
However, there is also growing concern about the implications the deployment of ML has for the future of health care and medicine. 

While there are ongoing public discussions about ML replacing humans as workers in many different ways \idea{[citation needed]}, many scholars have made clear that ML and AI tools will not replace clinicians in the near future but rather be integrated as support systems, for example as clinical decision support systems (CDSS) \cite{Morley2020}.

CDSS have been used since the 1980s with growing success \cite{sutton2020overview}.
Only in recent years, the involvement of Machine Learning in those systems has led to a new regulatory situation.
Still, their deployment and success can tell us a lot about the way to go with ML tools.
For example, although closed loop systems, i.e., systems were every step of the process from diagnosis to drug intake is computerized and monitored, do already exist they are not commonly used, partly due to costs but certainly also due to the involved surveillance environment for patients \cite{sutton2020overview}. 

% why medicine is an interesting field to clarify ethical problems, particularities
\idea{
    Peculiarities of health care as application field:
    inevitable moral dilemmas, impossibility of the ``do nothing'' solution, developed moral literature, high stakes, less readiness to sacrify performance, human comparisons.
    Allocation of positive goods might be different from prevention of harm, \eg in healthcare settings. Idea: harm distribution is different from benefit distribution.
    Trying to ensure equal harms in a setting where medicine can very well solve one group's problems seems illogical.
    true predictors: ``difference does not always entail inequality. In some instances, it is appropriate to incorporate differences between identities because there is a reasonable presumption of causation \cite[e221]{Mccradden2020}''
}

We consider CDSS a particularly interesting use case of ML when it comes to fairness and more generally ethical discussion, since the biomedical field historically played an important role when it comes to ethical principles and deliberations \cite{Toulmin1982}\cite{Hardin1989}.
It helped displace purely theoretical ethical deliberations (meta-ethics) to more concrete, unavoidable, and tangible questions (applied ethics).
It further helped replace purely relativist, subjectivist, and psychological investigations of ethics \cite{Toulmin1982}.
Broad, universal moral principles were replaced by case studies, for example arising in clinical medicine.
Finally, ethical considerations started taking into account the roles and relationships of the actors present (for example, by recognizing the authority relationship between doctors and patients).
Poetically put, ``Medicine saved the life of ethics'' \cite{Toulmin1982}.

% research questions
\idea{Add research questions}

% methods and preview
In our investigations, we draw on literature from the fields of fair-ML, economics, medicine, biomedical ethics, and philosophy.
We relate fairness problems raised by the Fair-ML community to ethical questions raised in the medical field.
An analysis of the medical literature helps us understand which problems are caused by the application of ML, and which problems are inherent to medical practice.
We look at well-known ethical principles from the biomedical literature to determine their usefulness in enlightening the ethical discussion about CDSS.
We consider the identified moral dilemmas as an issue of trade-offs, and examine economists' work on the topic for a meaningful formalization.
