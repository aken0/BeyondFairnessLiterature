\idea{
    \begin{itemize}
        \item We identify 3 sources of ethical discussion...
        \item Why not concentrate on one? All must be approached when the solution is implemented.
        \item Must be considered together, since they are not orthogonal axes. Eg., privacy might mean reducing the individual even more to group characteristics.
            Additionally, privacy and fairness might be in conflict: targeted data collection to correct data biases ``may pose ethical and privacy concerns as a result of additional surveillance'' \cite[p.~8]{Chen2021}.
    \end{itemize}
}

\subsection{Privacy and predictability}
\idea{
    \# TODO: specify content
    Non-maleficience, trade-off \cite{Dijkstra2020}.
}

\subsection{Group fairness and individual fairness}
\temp{
The elements to take into account when deciding on what metric of fairness to use are multiple.
On the one hand, we need to decide what moral principles we want to follow, i.~e.~what we intend by equal or just treatment.
What do we consider distributive justice?
What is the resource that has to be distributed?
Do we care about the end-result, or only about promising equal expectancies?
On the other hand, we have to provide a model about the sources of unfairness in the data and model we use.
In ML terms, we have to state our assumptions about the data-generating process.
For example, assuming historical bias means putting into question the validity of the training labels, and hence accuracy on them as a performance measure \cite[p.~6]{Rajkomar2018}.
}
\idea{
    \begin{itemize}
        \item Why we think Binns 2020 does not cancel the problem.
                cp. ``Given the epistemic uncertainty surrounding the association between protected identities and health outcomes, the use of fairness solutions can create empirical challenges'' \cite[e221]{Mccradden2020}.
                negative legacy, labeling prejudice, sample selection bias \cite[p.~6]{Chen2021}.
        \item Specificity of medicine: groups sometimes DO matter in the prediction. ``difference does not always entail inequality. In some instances, it is appropriate to incorporate differences between identities because there is a reasonable presumption of causation'' \cite[e221]{Mccradden2020}
                Importance of the ``causal structure between latent biological factors such as ancestry and their associated diseases across ethnic subpopulations'' \cite[p.~3]{Chen2021}.
        \item ML systems have the (demonstrated in practice) potential to discriminate, even if group information is not included, through for example leakage of ethnicity, which is then used as a shortcut to make the predictions (reproducing, or even amplifying, historical bias) \cite[p.~3]{Chen2021}.
                For this reason, so-called fairness through unawareness is insufficient in non-discrimination. \cite[p.~5]{Chen2021}.
    \end{itemize}
}

\subsection{Inequity and average performance}

\subsection{Fairness and prediction accuracy}
\idea{
    \begin{itemize}
        \item Specificity of medicine: allocation of physical benefits and harms. Non-maleficience?
        \item ``difference between an idealised model and non-ideal, real-world behavior affects metrics of model performance (eg, specificity, sensitivity) and clinical utility in practice.'' \cite[e221]{Dijkstra2020}.
    \end{itemize}
}
