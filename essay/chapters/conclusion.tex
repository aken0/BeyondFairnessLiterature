We were able to show that trade-offs are omnipresent in technology, that they usually cannot be avoided and that they can be formalized as Pareto optimality.
Three main trade-offs involving fairness were identified in ML: The choice of the fairness measure which involves the decision between individual and group fairness, the trade-off between accuracy and fairness which results from the fact that ensuring fairness often leads to a lower prediction accuracy, and the trade-off between privacy and accuracy, where ensuring privacy has the same effect as ensuring fairness.

A number of trade-offs can be identified in health care, at different levels, for example in policy, treatment, or research.
Often, trade-off situations are described in terms of moral dilemmas. We argued that they are fundamentally the same thing, but people tend to reject trade-off talk when sacred values (such as human life) are involved \cite{Tetlock2003}.
Fairness issues have been identified in the current practice of medicine, even when unaided by algorithmic tools. This is evident also from the fact that so-called biased data, partly responsible for algorithmic fairness issues, is generated in those situations.
While we should take inspiration from biomedical ethics literature, since fairness analysis is largely domain-dependent, we must at the same time recognize that principled approaches might lead to disagreement rather than solve it.

Many fairness-related issues identified in the fair-ML literature in medical applications are not strictly caused by ML. Rather, they are made more explicit by requiring mathematical formulations.
We hold that ML tools should be analyzed with respect to fairness relatively to human deciders (doctors), rather than with binary fair/not fair questions. Errors and imperfections have to be expected, and are unavoidable in stochastic situations. In this respect, care must be taken in recognizing double standards for humans and machines when present, keeping in mind the limitations of medicine as is practiced today.
ML can be used to actively improve fairness.
