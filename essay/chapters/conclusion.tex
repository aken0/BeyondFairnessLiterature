We were able to show that trade-offs are omnipresent in technology and that they usually cannot be avoided.
Then we introduced the notion of Pareto optimality to formalize trade-offs in general.
Three main trade-offs involving fairness were identified in ML: The choice of the fairness measure with both a moral decision and impossibility results between the measures, the trade-off between accuracy and fairness which stems from the fact that ensuring fairness often leads to a lower prediction accuracy, and the trade-off between privacy and accuracy, where ensuring privacy usually also leads to lower prediction accuracy, albeit for different reasons.

A number of trade-offs can be identified in health care, at different levels, for example in policy, treatment, or research.
Often, trade-off situations are described in terms of moral dilemmas. We argued that they are fundamentally the same thing, but people tend to reject trade-off talk when sacred values (such as human life) are involved \cite{Tetlock2003}.
Fairness issues have been identified in the current practice of medicine, even when unaided by algorithmic tools. This is evident also from the fact that so-called biased data, partly responsible for algorithmic fairness issues, is generated in those situations.
While we should take inspiration from biomedical ethics literature, since fairness analysis is largely domain-dependent, we must at the same time recognize that principled approaches might lead to disagreement rather than solve it.

Many fairness-related issues identified in the fair-ML literature in medical applications are not strictly caused by ML. Rather, they are made more explicit by requiring mathematical formulations.
We hold that ML tools should be analyzed with respect to fairness relatively to human deciders (doctors), rather than with binary fair/not fair questions. Errors and imperfections have to be expected, and are unavoidable in stochastic situations. In this respect, care must be taken in recognizing double standards for humans and machines when present, keeping in mind the limitations of medicine as is practiced today.
ML can be used to actively improve fairness.

Leaving the fairness domain behind, we were able to identify several ethical trade-offs that occur in a new light at the intersection of ML and medicine. This includes trade-offs between trust and accuracy, human involevment and accuracy, and monetary spendings and patient experience among others. However, while the technology of ML is certainly a special case in some ways, we argue that those trade-offs are not entirely new and that inspiration from other technologies can be used to find optimal solutions. In general, including what we have learned from the past will help us avoid mistakes and can speed up the way to ML systems being confidently (and securely) used as tools in medicine and health care.